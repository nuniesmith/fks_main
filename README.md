# FKS Trading Platform - Orchestrator & Monitor

[![Tests](https://github.com/nuniesmith/fks/actions/workflows/tests.yml/badge.svg)](https://github.com/nuniesmith/fks/actions/workflows/tests.yml)

**FKS Main** is the orchestrator and monitoring hub for an **8-service microservices architecture**. It provides centralized authentication, service registry, health monitoring, and Celery Beat scheduling for the entire FKS trading ecosystem.

> **Architecture**: Multi-repo microservices with FKS Main as orchestrator (October 2025)  
> **Status**: Phase 7.3 Complete âœ… | Phase 8.1 90% Complete ğŸš§  
> **AI System**: 7-agent LangGraph pipeline with local LLM (Ollama)  
> **Production**: Kubernetes-ready with Helm charts, auto-scaling, monitoring  
> **See**: [`PHASE_8_1_READY.md`](PHASE_8_1_READY.md) for K8s deployment  
> **Quick Start**: `make k8s-dev` for local Kubernetes testing

## ğŸš€ Quick Start

### Prerequisites

- **Docker** and **Docker Compose** installed
- **Kubernetes** (minikube/kind) for K8s deployment
- **Python 3.11+** for local development
- **PostgreSQL 15+** and **Redis** (or use Docker)

### Local Development (5 minutes)

```bash
# 1. Clone and setup
git clone https://github.com/nuniesmith/fks.git
cd fks

# 2. Install dependencies
make install

# 3. Start services with Docker Compose
make up

# 4. Run tests
make test

# 5. Access the platform
# - Web UI: http://localhost:3001
# - API Gateway: http://localhost:8001
# - Main Orchestrator: http://localhost:8000
```

### Kubernetes Deployment

```bash
# Start local K8s cluster
make k8s-dev

# Check cluster health
make k8s-status

# Access services via Ingress
# See docs/deployment/INGRESS_ACCESS_GUIDE.md
```

### Daily Development

```bash
# Run linting and tests
make lint && make test

# View service health
make health

# Check logs
make logs SERVICE=fks_app
```

## ğŸ“š Documentation

### Core Documentation

- **[Architecture Overview](docs/ARCHITECTURE.md)** - System design and service relationships
- **[Monorepo Structure](docs/MONOREPO_ARCHITECTURE.md)** - Directory organization
- **[AI Architecture](docs/AI_ARCHITECTURE.md)** - 7-agent LangGraph system details

### Deployment & Operations

- **[K8s Deployment Guide](docs/K8S_DEPLOYMENT_GUIDE.md)** - Production Kubernetes setup
- **[Ingress Access Guide](docs/deployment/INGRESS_ACCESS_GUIDE.md)** - Domain and TLS configuration
- **[Cluster Health](docs/operations/CLUSTER_HEALTHY.md)** - Health check procedures
- **[K8s Status Reports](docs/operations/K8S_STATUS_REPORT.md)** - Current cluster status

### Development Phases

- **[Phase 6 AI Complete](docs/PHASE_6_COMPLETE_SUMMARY.md)** - Multi-agent system implementation
- **[Phase 7.1 Complete](docs/PHASE_7_1_COMPLETE.md)** - LLM Judge integration
- **[Phase 7.2 Complete](docs/PHASE_7_2_COMPLETE_SUMMARY.md)** - Advanced AI features
- **[Next Steps](docs/NEXT_STEPS.md)** - Upcoming development roadmap

### Testing & Quality

- **[Browser Testing Guide](docs/BROWSER_TESTING_GUIDE.md)** - E2E testing procedures
- **[Optimization Guide](docs/OPTIMIZATION_GUIDE.md)** - Performance tuning
- **[Phase 3 Test Results](docs/PHASE_3_FUNCTIONAL_TESTING_RESULTS.md)** - Test coverage reports

### Integration Guides

- **[Canadian API Integration](docs/CANADIAN_API_INTEGRATION.md)** - TMX integration
- **[ASMBTR Compatibility](docs/ASMBTR_COMPATIBILITY.md)** - Legacy system support

## ğŸ¯ Microservices Architecture

### Service Overview

**FKS Main (This Repository)** - Orchestrator & Monitor
- **Role**: Service registry, health monitoring, centralized auth, Celery Beat scheduler
- **Port**: 8000 (Django + Gunicorn)
- **What It Does**: 
  - Monitors all microservices via health checks every 2 minutes
  - Provides service discovery endpoint for inter-service communication
  - Centralized authentication (delegates to fks_api for validation)
  - Celery Beat schedules periodic tasks across all services
- **What It Doesn't Do**: 
  - NO business logic (trading, signals, portfolio, etc.)
  - NO direct exchange communication
  - NO data collection or storage

**fks_api** - Thin API Gateway ([`repo/api/`](https://github.com/nuniesmith/api))
- **Role**: Routing, authentication, rate limiting
- **Port**: 8001 (FastAPI)
- **Responsibilities**: 
  - Route requests to appropriate services (fks_app, fks_data, fks_execution)
  - JWT authentication and API key validation
  - Rate limiting and request throttling
  - NO domain logic - pure gateway pattern

**fks_app** - Business Logic Service ([`repo/app/`](https://github.com/nuniesmith/app))
- **Role**: ALL trading logic, strategies, signals, portfolio management
- **Port**: 8002 (FastAPI)
- **Responsibilities**:
  - Strategy development and backtesting
  - Signal generation (RSI, MACD, Bollinger Bands, etc.)
  - Portfolio optimization with Optuna
  - Celery tasks for async operations
  - Queries fks_ai for ML predictions and RAG insights

**fks_ai** - AI/ML/RAG Service ([`repo/ai/`](https://github.com/nuniesmith/ai))
- **Role**: Multi-agent trading intelligence with LangGraph + Ollama + ChromaDB
- **Port**: 8007 (FastAPI)
- **GPU**: CUDA-enabled for local LLM inference
- **Phase 6 Complete** (Oct 31, 2025): 7 specialized agents, StateGraph orchestration, 88 tests
- **Responsibilities**:
  - **Multi-Agent System**: 4 analysts (Technical, Sentiment, Macro, Risk) + 3 debaters (Bull, Bear, Manager)
  - **StateGraph Pipeline**: Analysts â†’ Debate â†’ Manager â†’ Signal â†’ Reflection
  - **ChromaDB Memory**: Persistent decision storage with semantic search
  - **Risk Management**: Position sizing, stop-loss, take-profit calculation
  - Local LLM inference with Ollama/llama.cpp (llama3.2:3b)
  - RAG system with pgvector semantic search
  - Embeddings generation (sentence-transformers + OpenAI fallback)
  - Document processing and chunking
  - ML model training and forecasting
  - Zero-cost AI inference (no API fees)

**fks_data** - Data Collection Service ([`repo/data/`](https://github.com/nuniesmith/data))
- **Role**: Always-on market data collection and caching
- **Port**: 8003 (FastAPI)
- **Responsibilities**:
  - Continuous data collection for enabled assets
  - CCXT integration with Binance, Kraken, etc.
  - TimescaleDB storage with hypertables
  - Redis caching for fast queries
  - Other services query fks_data, NEVER exchanges directly

**fks_execution** - Execution Engine ([`repo/execution/`](https://github.com/nuniesmith/execution))
- **Role**: High-performance order execution
- **Port**: 8004 (Rust - Actix-web/Axum)
- **Responsibilities**:
  - ONLY service that talks to exchanges/brokers
  - Order lifecycle management with FSM
  - Position tracking and updates
  - Fast, reliable execution with circuit breaker

**fks_ninja** - NinjaTrader Bridge ([`repo/ninja/`](https://github.com/nuniesmith/ninja))
- **Role**: Bridge between FKS and NinjaTrader 8 for prop firm futures trading
- **Port**: 8005 (C# .NET)
- **Responsibilities**:
  - Receive signals from fks_app
  - Forward to NinjaTrader 8 via AT Interface
  - NinjaTrader indicators and strategies
  - Support prop firm accounts (FXIFY, Topstep, etc.)

**fks_web** - Web UI ([`repo/web/`](https://github.com/nuniesmith/web))
- **Role**: User interface with Django templates
- **Port**: 3001 (Django or Vite)
- **Responsibilities**:
  - Dashboard, strategies, signals, portfolio views
  - Bootstrap 5 templates with Mermaid diagrams
  - All data fetched via fks_api (no direct DB queries)
  - Real-time updates with WebSocket

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FKS Main                            â”‚
â”‚              (Orchestrator & Monitor)                       â”‚
â”‚  - Service Registry                                         â”‚
â”‚  - Health Monitoring                                        â”‚
â”‚  - Centralized Auth                                         â”‚
â”‚  - Celery Beat Scheduler                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚                 â”‚
          â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚fks_api  â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚ fks_app  â”‚â—„â”€â”€â”€â–ºâ”‚fks_data  â”‚
    â”‚Gateway  â”‚       â”‚Business  â”‚     â”‚Collector â”‚
    â”‚         â”‚       â”‚Logic     â”‚     â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚
          â”‚                 â–¼                 â”‚
          â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
          â”‚           â”‚ fks_ai   â”‚            â”‚
          â”‚           â”‚GPU/ML/RAGâ”‚            â”‚
          â”‚           â”‚          â”‚            â”‚
          â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
          â”‚                 â”‚                 â”‚
          â”‚                 â–¼                 â”‚
          â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚fks_exec  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚Rust      â”‚
                      â”‚Engine    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                      [Exchanges]
                      Binance, Kraken, etc.

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚fks_ninja â”‚
          â”‚NT Bridge â”‚â—„â”€â”€â”€ Signals from fks_app
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
          [NinjaTrader 8] â†’ [Prop Firms]
```

**Market Data Flow**: `Exchanges â†’ fks_data (collect) â†’ TimescaleDB/Redis â†’ fks_app (query)`  
**Signal Execution**: `fks_app (signal) â†’ fks_execution (order) â†’ Exchange â†’ fks_app (fill)`  
**AI/ML Flow**: `fks_app (request) â†’ fks_ai (GPU inference/RAG) â†’ fks_app (prediction/insight)`  
**External API**: `Client â†’ fks_api (auth) â†’ fks_app (logic) â†’ fks_data (data) â†’ fks_api (response)`  
**NinjaTrader**: `fks_app (signal) â†’ fks_ninja (bridge) â†’ NinjaTrader 8 â†’ Prop Firm`

## ğŸ“ Project Structure (FKS Main Only)

```
fks/  (THIS REPOSITORY - Orchestrator only)
â”œâ”€â”€ manage.py                  # Django CLI
â”œâ”€â”€ docker-compose.yml         # Multi-service orchestration
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Makefile                   # Development commands
â”œâ”€â”€ pytest.ini                 # Test configuration
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile            # FKS Main container
â”‚   â””â”€â”€ Dockerfile.gpu        # GPU-accelerated image (for RAG)
â”‚
â”œâ”€â”€ repo/                      # Git submodules (microservices)
â”‚   â”œâ”€â”€ api/                  # fks_api service (FastAPI gateway)
â”‚   â”œâ”€â”€ app/                  # fks_app service (business logic)
â”‚   â”œâ”€â”€ ai/                   # fks_ai service (GPU-accelerated ML/RAG)
â”‚   â”œâ”€â”€ data/                 # fks_data service (data collection)
â”‚   â”œâ”€â”€ execution/            # fks_execution service (Rust engine)
â”‚   â”œâ”€â”€ ninja/                # fks_ninja service (NinjaTrader bridge)
â”‚   â””â”€â”€ web/                  # fks_web service (Django UI)
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ init.sql              # TimescaleDB schema + hypertables
â”‚
â”œâ”€â”€ src/                       # FKS Main Django app (orchestrator only)
â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â””â”€â”€ django/           # Django project settings
â”‚   â”‚       â”œâ”€â”€ settings.py   # Configuration
â”‚   â”‚       â”œâ”€â”€ urls.py       # URL routing
â”‚   â”‚       â”œâ”€â”€ wsgi.py       # WSGI application
â”‚   â”‚       â””â”€â”€ celery.py     # Celery configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ monitor/              # âœ… Service registry & health monitoring
â”‚   â”‚   â”œâ”€â”€ models.py         # Service, HealthCheck models
â”‚   â”‚   â”œâ”€â”€ services.py       # HealthMonitorService, ServiceRegistry
â”‚   â”‚   â”œâ”€â”€ tasks.py          # Celery health check tasks
â”‚   â”‚   â”œâ”€â”€ views.py          # Health dashboard, API endpoints
â”‚   â”‚   â””â”€â”€ admin.py          # Django admin
â”‚   â”‚
â”‚   â”œâ”€â”€ authentication/       # âœ… Centralized auth (delegates to fks_api)
â”‚   â”‚   â”œâ”€â”€ models.py         # User, APIKey models
â”‚   â”‚   â”œâ”€â”€ middleware.py     # Auth middleware
â”‚   â”‚   â”œâ”€â”€ views.py          # Login/logout views
â”‚   â”‚   â””â”€â”€ admin.py          # Django admin
â”‚   â”‚
â”‚   â”œâ”€â”€ framework/            # âš ï¸ Shared utilities (evaluate for extraction)
â”‚   â”‚   â”œâ”€â”€ middleware/       # Circuit breaker, rate limiter, metrics
â”‚   â”‚   â”œâ”€â”€ exceptions/       # Custom exception hierarchy
â”‚   â”‚   â”œâ”€â”€ services/         # Service templates & registry
â”‚   â”‚   â”œâ”€â”€ config/           # Configuration management
â”‚   â”‚   â”œâ”€â”€ cache/            # Caching abstraction
â”‚   â”‚   â””â”€â”€ lifecycle/        # App lifecycle hooks
â”‚   â”‚
â”‚   â””â”€â”€ core/                 # âš ï¸ Minimal shared models (evaluate for extraction)
â”‚       â”œâ”€â”€ models/           # Base models (if any)
â”‚       â””â”€â”€ utils/            # Helper functions
â”‚
â”œâ”€â”€ archive/                   # âœ… Archived legacy monolith code
â”‚   â””â”€â”€ legacy_monolith/
â”‚       â”œâ”€â”€ README.md         # Documentation of archive
â”‚       â”œâ”€â”€ app.py            # Old FastAPI monolith entry point
â”‚       â”œâ”€â”€ engine/           # Old trading engine
â”‚       â”œâ”€â”€ infrastructure/   # Old infrastructure
â”‚       â”œâ”€â”€ services/         # Old service layer
â”‚       â”œâ”€â”€ api/              # Old API routes
â”‚       â”œâ”€â”€ trading/          # Old trading logic
â”‚       â””â”€â”€ data/             # Old data handling
â”‚
â”œâ”€â”€ tests/                     # Test suite (orchestrator tests only)
â”‚   â”œâ”€â”€ unit/                 # Unit tests
â”‚   â””â”€â”€ integration/          # Integration tests
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ SERVICE_CLEANUP_PLAN.md   # 7-phase migration plan
â”‚   â”œâ”€â”€ ARCHITECTURE.md           # Architecture documentation
â”‚   â”œâ”€â”€ QUICKSTART.md             # Quick start guide
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ logs/                      # Application logs
â”œâ”€â”€ monitoring/                # Prometheus/Grafana config
â”‚   â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ grafana/
â”‚
â””â”€â”€ scripts/                   # Utility scripts
    â”œâ”€â”€ setup.sh
    â””â”€â”€ ...
```

### Microservice Repositories (Git Submodules)

Each service is a separate Git repository under `repo/`:

- **`repo/api/`** ([github.com/nuniesmith/api](https://github.com/nuniesmith/api)) - Thin API gateway
- **`repo/app/`** ([github.com/nuniesmith/app](https://github.com/nuniesmith/app)) - Business logic service
- **`repo/ai/`** ([github.com/nuniesmith/ai](https://github.com/nuniesmith/ai)) - GPU-accelerated ML/RAG service
- **`repo/data/`** ([github.com/nuniesmith/data](https://github.com/nuniesmith/data)) - Data collection service
- **`repo/execution/`** ([github.com/nuniesmith/execution](https://github.com/nuniesmith/execution)) - Rust execution engine
- **`repo/ninja/`** ([github.com/nuniesmith/ninja](https://github.com/nuniesmith/ninja)) - NinjaTrader C# bridge
- **`repo/web/`** ([github.com/nuniesmith/web](https://github.com/nuniesmith/web)) - Django web UI

## ğŸš€ Quick Start

### Prerequisites

- **Docker & Docker Compose** (v24+ recommended)
- **Git** (for submodule management)
- **WSL** (for Windows users)

### 1. Clone with Submodules

```bash
# Clone FKS Main with all microservice submodules
git clone --recurse-submodules https://github.com/nuniesmith/fks.git
cd fks

# Or if already cloned, initialize submodules
git submodule update --init --recursive
```

### 2. Security Setup (CRITICAL!)

**ğŸ”’ Generate secure passwords before starting:**

```bash
# Run the security setup helper
make security-setup

# This generates strong passwords and creates .env file
# NEVER commit .env to git!
```

This will:

- Generate strong passwords using OpenSSL
- Create/update your `.env` file with secure credentials
- Enable PostgreSQL SSL and Redis authentication
- Verify `.env` is not tracked by git

**âš ï¸ Never use default passwords in production!**

### 3. Configure Environment

Your `.env` file should have strong passwords (generated by `make security-setup`):

```env
# Generated by security setup
POSTGRES_PASSWORD=<secure-random-password>
REDIS_PASSWORD=<secure-random-password>
DJANGO_SECRET_KEY=<secure-random-key>
PGADMIN_PASSWORD=<secure-random-password>
GRAFANA_PASSWORD=<secure-random-password>

# PostgreSQL SSL enabled by default
POSTGRES_SSL_ENABLED=on
POSTGRES_HOST_AUTH_METHOD=scram-sha-256

# Optional external services
DISCORD_WEBHOOK_URL=  # Optional - Discord notifications
BINANCE_API_KEY=      # Optional - Binance API
BINANCE_API_SECRET=   # Optional - Binance API
OPENAI_API_KEY=       # Optional - RAG system fallback
TAILSCALE_AUTH_KEY=   # Optional - VPN access
```

### 4. Start All Services

```bash
# Start all 8 microservices + infrastructure (standard mode)
make up

# Or with GPU support for fks_ai (Ollama LLM + ML inference)
make gpu-up

# View logs for all services
make logs

# View logs for specific service
docker-compose logs -f fks_api
docker-compose logs -f fks_app
docker-compose logs -f fks_ai  # GPU ML/RAG service
```

**GPU Requirements** (for `make gpu-up`):
- NVIDIA GPU with CUDA 12.2+ support
- nvidia-docker2 runtime installed
- At least 8GB VRAM for LLM models

### 5. Access Services

**FKS Main (Orchestrator)**:

- Health Dashboard: <http://localhost:8000/health/dashboard/>
- Service Registry: <http://localhost:8000/monitor/api/services/>
- Django Admin: <http://localhost:8000/admin>

**Microservices**:

- fks_api (Gateway): <http://localhost:8001/docs> (Swagger UI)
- fks_app (Business Logic): <http://localhost:8002/docs>
- fks_data (Data Collection): <http://localhost:8003/health>
- fks_execution (Rust Engine): <http://localhost:8004/health>
- fks_ninja (NinjaTrader): <http://localhost:8005/health>
- fks_ai (GPU/ML/RAG): <http://localhost:8007/docs>
- fks_web (Web UI): <http://localhost:3001>

**Infrastructure**:

- Grafana (Monitoring): <http://localhost:3000> (admin/admin)
- Prometheus (Metrics): <http://localhost:9090>
- pgAdmin (Database): <http://localhost:5050>
- Flower (Celery): <http://localhost:5555>

### 6. Verify System Health

```bash
# Check all services are healthy
make multi-status

# Or manually check health dashboard
curl http://localhost:8000/health/dashboard/ | jq

# Run orchestrator tests
pytest tests/unit/ -v
```

### 7. Development Workflow

```bash
# Stop all services
make down

# Restart specific service after code changes
docker-compose restart fks_app

# Rebuild service after dependency changes
docker-compose up -d --build fks_app

# Enter service shell
docker-compose exec fks_app bash

# View service logs
docker-compose logs -f fks_app
```

## ğŸ”’ Security Features

### Implemented Security Hardening
- **django-axes**: Login attempt tracking and lockout (5 attempts, 1-hour cooldown)
- **django-ratelimit**: API rate limiting (100/hour anon, 1000/hour authenticated)
- **PostgreSQL SSL**: TLS encryption with scram-sha-256 authentication
- **Redis Authentication**: Password-protected Redis connections
- **Strong Passwords**: All credentials use `openssl rand -base64` generation
- **Security Headers**: HSTS, XSS filter, content-type nosniff, X-Frame-Options
- **Session Security**: HTTP-only, SameSite cookies with Redis-backed sessions

### Security Checklist Before Production
- [ ] Run `make security-setup` to generate strong passwords
- [ ] Verify `.env` is NOT in git: `git log --all -- .env`
- [ ] Change default Grafana password (admin/admin)
- [ ] Set up HTTPS/SSL certificates for nginx
- [ ] Remove exposed ports (5432, 6379) from docker-compose.yml
- [ ] Run `pip-audit -r requirements.txt` for vulnerability scan
- [ ] Enable automated backups
- [ ] Set up monitoring alerts

See [`docs/SECURITY_AUDIT.md`](docs/SECURITY_AUDIT.md) for complete security documentation.

## ğŸ“Š Database Schema

### Hypertables (Optimized for Time-Series)

1. **ohlcv_data** - Market data for all symbols/timeframes
   - Partitioned by time
   - Compressed after 7 days
   - Indexes: symbol, timeframe, time

2. **trades** - Complete trade history
   - Partitioned by time
   - Tracks all executions with PnL

3. **balance_history** - Account balance snapshots
   - Partitioned by time
   - Compressed after 30 days
   - Used for equity curves

4. **indicators_cache** - Pre-calculated technical indicators
   - Partitioned by time
   - Improves backtest performance

### Regular Tables

5. **accounts** - Personal and prop firm accounts
6. **positions** - Current open positions
7. **sync_status** - Data synchronization state
8. **strategy_parameters** - Optimized strategy configs

### Continuous Aggregates (Materialized Views)

- **daily_account_performance** - Pre-aggregated daily metrics
  - Win rate, total PnL, average trade, fees
  - Auto-refreshes every hour

## ğŸ”§ Usage

### Data Sync Service

```bash
# Initial full sync (2 years of data)
docker-compose run --rm web python data_sync_service.py init

# Update latest data only
docker-compose run --rm web python data_sync_service.py update

# Run continuous sync (updates every 60 seconds)
docker-compose run --rm web python data_sync_service.py continuous

# Check sync status
docker-compose run --rm web python data_sync_service.py status
```

### Database Management

**Using pgAdmin** (http://localhost:5050):

1. Login with credentials from `.env`
2. Add server:
   - Name: Crypto DB
   - Host: db
   - Port: 5432
   - Username: (from .env)
   - Password: (from .env)

3. Explore tables, run queries, view hypertable stats

**Direct PostgreSQL Access**:

```bash
# Connect to database
docker-compose exec db psql -U fks_user -d fks_db

# View tables
\dt

# Check hypertable info
SELECT * FROM timescaledb_information.hypertables;

# Check compression stats
SELECT * FROM timescaledb_information.compression_settings;

# View recent OHLCV data
SELECT * FROM ohlcv_data 
WHERE symbol = 'BTCUSDT' AND timeframe = '1h' 
ORDER BY time DESC LIMIT 10;
```

### Python API Examples

```python
from db_utils import *
from datetime import datetime, timedelta

# Get OHLCV data as DataFrame
df = get_ohlcv_data('BTCUSDT', '1h', limit=1000)

# Create an account
account = create_account(
    name='My Trading Account',
    account_type='personal',
    initial_balance=10000.0,
    broker='Binance'
)

# Get all accounts
accounts = get_accounts()

# Record a trade
trade = record_trade(
    account_id=1,
    symbol='BTCUSDT',
    trade_type='BUY',
    quantity=0.1,
    price=45000.0,
    fee=4.5,
    order_type='MARKET'
)

# Get account balance history
balance_df = get_balance_history(account_id=1, limit=30)

# Check sync status
status = get_sync_status(symbol='BTCUSDT')
```

## ğŸ› ï¸ Development

### Add New Symbol

1. Edit `src/config.py`:
```python
MAINS = ['BTCUSDT', 'ETHUSDT']
ALTS = ['SOLUSDT', 'AVAXUSDT', 'SUIUSDT', 'NEWCOINUSDT']
```

2. Add sync status records:
```bash
docker-compose exec db psql -U fks_user -d fks_db -c "
INSERT INTO sync_status (symbol, timeframe, sync_status)
SELECT 'NEWCOINUSDT', tf, 'pending'
FROM unnest(ARRAY['1m','5m','15m','30m','1h','4h','1d','1w','1M']) AS tf
ON CONFLICT DO NOTHING;"
```

3. Sync data:
```bash
docker-compose run --rm web python data_sync_service.py init
```

### Database Migrations

For schema changes, use Alembic:

```bash
# Generate migration
docker-compose run --rm web alembic revision --autogenerate -m "description"

# Apply migration
docker-compose run --rm web alembic upgrade head
```

## ğŸ§ª Testing

### Run Backtest

```bash
# Access the web interface
# Navigate to "Optimization & Backtest" tab
# Pull data, optimize parameters, run backtest
```

### Check Data Quality

```sql
-- Check for gaps in data
SELECT symbol, timeframe, 
       COUNT(*) as candles,
       MIN(time) as oldest,
       MAX(time) as newest,
       MAX(time) - MIN(time) as time_range
FROM ohlcv_data
GROUP BY symbol, timeframe
ORDER BY symbol, timeframe;

-- Check for null values
SELECT symbol, timeframe, COUNT(*) 
FROM ohlcv_data 
WHERE close IS NULL OR volume IS NULL
GROUP BY symbol, timeframe;
```

## ğŸ“ˆ Performance Optimization

TimescaleDB automatically optimizes for:
- **Compression**: Data older than 7 days is compressed (20-90% reduction)
- **Chunking**: Data is partitioned in time-based chunks
- **Indexing**: Optimized indexes for time-series queries
- **Continuous Aggregates**: Pre-computed metrics for fast queries

### Query Performance Tips

```sql
-- Use time-based WHERE clauses
SELECT * FROM ohlcv_data
WHERE symbol = 'BTCUSDT' 
  AND timeframe = '1h'
  AND time > NOW() - INTERVAL '30 days';

-- Leverage continuous aggregates
SELECT * FROM daily_account_performance
WHERE account_id = 1 
  AND day > NOW() - INTERVAL '90 days';
```

## ğŸ› Troubleshooting

### Database Connection Issues
```bash
# Check database is running
docker-compose ps

# View database logs
docker-compose logs db

# Restart database
docker-compose restart db
```

### Data Sync Errors
```bash
# Check sync status
docker-compose run --rm web python data_sync_service.py status

# Re-sync specific symbol
docker-compose run --rm web python -c "
from data_sync_service import DataSyncService
service = DataSyncService()
service.sync_historical_data('BTCUSDT', '1h')
"
```

### Clear All Data and Restart
```bash
# Stop services
docker-compose down

# Remove volumes (WARNING: deletes all data!)
docker volume rm fks_postgres_data fks_redis_data fks_pgadmin_data

# Restart
./setup_database.sh
docker-compose run --rm web python data_sync_service.py init
docker-compose up -d
```

## ğŸ“ Useful Commands

```bash
# View all containers
docker-compose ps

# View logs
docker-compose logs -f [service_name]

# Restart service
docker-compose restart [service_name]

# Stop all services
docker-compose down

# Rebuild after code changes
docker-compose up -d --build

# Access Python shell with DB access
docker-compose run --rm web python
```

## ğŸ” Security Notes

- Never commit `.env` file
- Use strong passwords for database
- Encrypt API keys in production
- Restrict database access in production
- Enable SSL for PostgreSQL in production

## ğŸ“š Next Steps

1. âœ… Database setup complete
2. âœ… Historical data sync ready
3. â³ Add WebSocket support for real-time prices
4. â³ Implement persistent session state
5. â³ Add more trading strategies
6. â³ Build portfolio analytics dashboard
7. â³ Add automated trading capabilities

## ğŸ“– Resources

- [TimescaleDB Documentation](https://docs.timescale.com/)
- [Binance API Documentation](https://binance-docs.github.io/apidocs/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [TA-Lib Documentation](https://ta-lib.org/)

## ğŸ“§ Support

For issues or questions, check the logs and database status first:
```bash
docker-compose logs
docker-compose exec db psql -U fks_user -d fks_db -c "SELECT version();"
```
